# Computer Vision Test

## Task 1: Read in the attached image file: three_ships_horizon.JPG

Using `cv2.imread` to read the provided image: three_ships_horizon.JPG

## Task 2: Detect the horizon in the image

- Using Canny method to detect the edges of the image
- Using Hough algorithm to detect the straight line
- However Hough line does not perform very well and cannot provide all the line of horizon so:
    - Instead of create line, I create several data points representing horizon line generated by Hough

    ![new](https://github.com/user-attachments/assets/fd50e2c1-169f-4970-ad95-3b02d0455d3c)

    - Filtering the noises and redundant data points by using IQR method if y-axis of those significantly deviate compared to others
    - Using Linear Regression from those filtered data points to create a best suit line representing the horizon

    ![new](https://github.com/user-attachments/assets/f0970d0c-3ad8-4558-bc27-95ceae42a836)

## Task 3: Rotate the image to adjust the horizon to be level
Having the horizon line detected:
- Using start point (x1, y1) and end point (x2, y2) to calculate the angle with the horizontal level of the image to rotate

![rotated_image](https://github.com/user-attachments/assets/831ce688-592d-447b-85e8-18fe598458e8)

## Task 4: Crop the image down to remove blank pixels created by rotation
Crop the image so that it will remove all blank pixels by using:
- Find a threshold then using `cv2.findNonZero` and `cv2.boundingRect` to find the new parameters (x,y,w,h) for the image

## Task 5 & 6: Apply an edge detection algorithm to detect the three ship and Place bounding boxes around these ships then save as a tiff file
For this object detection, I am using:
- Richer Convolutional Features for Edge Detection -> Using this method, I can find the edges clearer and won't contain lots of noises like Canny, HED ...

![image](https://github.com/user-attachments/assets/01165288-7730-4afb-a1d2-1669e4a5df05)

- After achieve the black and white image with just edges, we can see the ship clearer. Then for filtering the horizon line just in case it will affect the ship detection, we will erase it by drawing the white line on it like this:

![image_with_white_line1](https://github.com/user-attachments/assets/9d555ddb-76d9-4045-a3ba-55ebd1a4eae7)

- Then using `cv2.erode` method supported by opencv to reduce noises and enhance the ships like this: 

![final](https://github.com/user-attachments/assets/63a0d287-1f6a-478c-bacd-a31c598e0481)

- After that using `cv2.getStructuringElement` and `cv2.morphologyEx` to improve the thickness edge of the ship and also re-connect the boundary line of the ships:

![final_dilate](https://github.com/user-attachments/assets/5bb1fedf-3a78-4ea2-83ff-41f21d1050dc)

- Then using the `cv2.connectedComponentsWithStats` to draw the bounding box all of the high density white pixel in the image. At first, it will detect so many noises (wave in the sea) as our object (ships):

![init_bbox](https://github.com/user-attachments/assets/19c9c112-dd74-4f80-bb0c-3b7cdb46a715)

- Filtering all the redundant object my limiting the dimension of the bounding boxes (if it is too small or too big, it will be noises). 
- I also do 1 more method to filter the noise by expanding the bounding box to some certain ratio, If amount of white pixels in that box does not change that means it is our object (Why is that because the wave in the sea tend to have a trend to be close to each other and very crowed).

After filtering the bounding boxes, I have the correct bounding boxes for the correct ships:

![final_bbox](https://github.com/user-attachments/assets/aa3b58d2-fc44-4b17-a5de-3e6cf2dc5609)

Then draw it back to our first image:

![three_ships_boxed](https://github.com/user-attachments/assets/220ab720-6a40-4923-af34-2282a73fef11)


## Instructions for Repo
### Repo structure
```
├── data
│   └── three_ships_horizon.JPG
├── LICENSE
├── models
│   └── bsds500_pascal_model.pth
├── README.md
├── requirements.txt
├── research
│   └── notebook.ipynb
└── src
    ├── config
    │   ├── configuration.py
    ├── exception.py
    ├── logger.py
    ├── modules
    │   ├── crop_img
    │   │   ├── crop.py
    │   ├── detect_horizon
    │   │   ├── horizon.py
    │   ├── detect_ships
    │   │   ├── dataset.py
    │   │   ├── model.py
    │   │   └── ship_detection.py
    │   ├── load_img
    │   │   └── read_img.py
    │   └── rotate_img
    │       └── rotate_image.py
    ├── pipeline
    │   └── main_pipeline.py
    └── utils.py
```

### Installation
Run the following command for installing necessary dependencies:
```
conda create --name {ENV-NAME} python=3.10 -y
conda activate {ENV-NAME}
pip install -r requirements.txt
```

### How to run
Please create `models` folder inside containing the pre-trained model for RCF [located here](https://drive.google.com/file/d/19EDBMFN6SBblOT8oOnf2lU0g8bshWiW8/view?usp=sharing)

In the same level with `src` folder create `.env` with the following line:
```
export PYTHONPATH="$PYTHONPATH:$PWD"
```

Then in the terminal at same level where we place the `.env` file typing this command: 
```
set -a
source .env
```

Finally, run the all of the stages like the demonstation following, using this command:
```
python src/pipeline/main_pipeline.py
```

All of the results will be saved in `results` folder.
